# ai_analyzer_qwen.py v2.3.0 - COM SUPORTE GROQCLOUD + STRUCTURED OUTPUT
"""
AI Analyzer para eventos de mercado com valida√ß√£o de dados.

üîπ NOVIDADES v2.3.0:
  ‚úÖ Structured Output focado em regi√µes de entrada:
     - sentiment, confidence, action
     - entry_zone, invalidation_zone, region_type
  ‚úÖ Prompts ajustados para foco em:
     - suporte / resist√™ncia
     - absor√ß√£o / exaust√£o
     - falta de demanda / oferta
     - pontos claros de entrada e zonas de defesa/invalida√ß√£o

üîπ NOVIDADES v2.2.0:
  ‚úÖ Suporte a Structured Output (JSON Mode) para Groq/OpenAI (se Pydantic dispon√≠vel)
  ‚úÖ Templates de prompt com Jinja2 (se dispon√≠vel), com fallback para f-strings
  ‚úÖ Cliente ass√≠ncrono AsyncOpenAI para Groq/OpenAI (usado internamente via asyncio.run)

üîπ NOVIDADES v2.1.0:
  ‚úÖ Suporte completo ao GroqCloud (PRIORIDADE 1)
  ‚úÖ Fallback inteligente: Groq ‚Üí OpenAI ‚Üí DashScope ‚Üí Mock
  ‚úÖ Valida√ß√£o autom√°tica de chave Groq
  ‚úÖ Logs detalhados de qual provedor est√° ativo

üîπ CORRE√á√ïES v2.0.2 (mantidas):
  ‚úÖ M√©todo analyze() adicionado para compatibilidade com main.py
  ‚úÖ Corrige extra√ß√£o de orderbook (pega do lugar certo)
  ‚úÖ Valida orderbook_data ANTES de formatar
  ‚úÖ Detecta contradi√ß√µes corretamente (volumes vs ratio)
  ‚úÖ Logs mais claros sobre fonte dos dados
  ‚úÖ Fallback para m√∫ltiplos caminhos de dados
  ‚úÖ System prompt melhorado
"""

import logging
import os
import random
import time
import asyncio
from typing import Any, Dict, Optional, Literal

from dotenv import load_dotenv

from format_utils import (
    format_price,
    format_quantity,
    format_percent,
    format_large_number,
    format_delta,
    format_time_seconds,
    format_scientific
)

try:
    import config as app_config
except Exception:
    app_config = None

# OpenAI / Groq (cliente s√≠ncrono + ass√≠ncrono)
try:
    from openai import OpenAI, AsyncOpenAI
    OPENAI_AVAILABLE = True
    ASYNC_OPENAI_AVAILABLE = True
except Exception:
    try:
        from openai import OpenAI  # type: ignore
        OPENAI_AVAILABLE = True
    except Exception:
        OPENAI_AVAILABLE = False
    ASYNC_OPENAI_AVAILABLE = False
    AsyncOpenAI = None  # type: ignore

# DashScope
try:
    from dashscope import Generation
    import dashscope
    DASHSCOPE_AVAILABLE = True
except Exception:
    DASHSCOPE_AVAILABLE = False

# Jinja2 para templates (opcional)
try:
    from jinja2 import Environment, BaseLoader
    JINJA_AVAILABLE = True
except Exception:
    JINJA_AVAILABLE = False
    Environment = None  # type: ignore
    BaseLoader = object  # type: ignore

# Pydantic para structured output (opcional)
try:
    from pydantic import BaseModel
    PYDANTIC_AVAILABLE = True
except Exception:
    PYDANTIC_AVAILABLE = False
    BaseModel = object  # type: ignore

from time_manager import TimeManager

load_dotenv()

# ========================
# Structured Output Schema
# ========================

if PYDANTIC_AVAILABLE:
    class AITradeAnalysis(BaseModel):
        """
        Esquema estruturado para a resposta da IA.

        Focado em:
        - dire√ß√£o (sentiment)
        - for√ßa (confidence)
        - a√ß√£o sugerida (action)
        - regi√£o de entrada / zona de defesa (entry_zone)
        - zona de invalida√ß√£o (invalidation_zone)
        - tipo de regi√£o (region_type: suporte/resist√™ncia/absor√ß√£o/exaust√£o/etc.)
        """
        sentiment: Literal["bullish", "bearish", "neutral"]
        confidence: float  # 0.0‚Äì1.0
        action: Literal["buy", "sell", "hold", "flat", "wait", "avoid"]
        rationale: str
        entry_zone: Optional[str] = None
        invalidation_zone: Optional[str] = None
        region_type: Optional[str] = None
else:
    AITradeAnalysis = None  # type: ignore


# ========================
# Jinja2 Templates
# ========================

if JINJA_AVAILABLE:
    _jinja_env = Environment(loader=BaseLoader(), trim_blocks=True, lstrip_blocks=True)
else:
    _jinja_env = None

ORDERBOOK_TEMPLATE = """
üß† **An√°lise Institucional ‚Äì {{ ativo }} | {{ tipo_evento }}**

üìù Descri√ß√£o: {{ descricao }}
{{ ob_str }}{{ ml_str }}{{ vp_str }}{{ order_flow_str }}

üìà Multi-Timeframes
{{ multi_tf_str }}

‚è≥ Mem√≥ria de eventos
{{ memoria_str }}

üìâ Probabilidade Hist√≥rica
   Long={{ prob_long }} | Short={{ prob_short }} | Neutro={{ prob_neutral }}

üéØ Tarefa
CR√çTICO: Se dados estiverem marcados como "Indispon√≠vel" ou "‚ö†Ô∏è", N√ÉO os use.

{% if not is_orderbook_valid %}
üî¥ ORDERBOOK INDISPON√çVEL - Use APENAS m√©tricas de fluxo (net_flow, flow_imbalance, tick_rule)
{% endif %}

Foque em:
1) Identificar regi√µes importantes:
   - suportes/resist√™ncias relevantes
   - √°reas de absor√ß√£o (defesa) e exaust√£o (fraqueza)
   - buracos de liquidez (falta de demanda/oferta)
2) Sugerir, SE HOUVER clareza, uma regi√£o aproximada de entrada (entry_zone) e uma zona de invalida√ß√£o (invalidation_zone).
3) Se o cen√°rio n√£o estiver claro, recomende aguardar (sem for√ßar trade).

Se dados cr√≠ticos faltarem, seja expl√≠cito sobre limita√ß√µes.
"""

DEFAULT_TEMPLATE = """
üß† **An√°lise Institucional ‚Äì {{ ativo }} | {{ tipo_evento }}**

üìù Descri√ß√£o: {{ descricao }}

   Pre√ßo: {{ preco_fmt }}
   Delta: {{ delta_line }}
   Volume: {{ vol_line }}
{{ ml_str }}{{ vp_str }}{{ order_flow_str }}

üìà Multi-Timeframes
{{ multi_tf_str }}

‚è≥ Mem√≥ria de eventos
{{ memoria_str }}

üìâ Probabilidade Hist√≥rica
   Long={{ prob_long }} | Short={{ prob_short }} | Neutro={{ prob_neutral }}

üéØ Tarefa
Use APENAS dados explicitamente fornecidos.
Se marcado como "Indispon√≠vel", N√ÉO use na an√°lise.

Foque em:
1) For√ßa ou fraqueza do movimento (sentimento).
2) Presen√ßa de regi√£o de defesa (suporte/absor√ß√£o) ou oferta (resist√™ncia/exaust√£o).
3) Se houver cen√°rios claros, descreva:
   - regi√£o aproximada de entrada (entry_zone)
   - zona de invalida√ß√£o (invalidation_zone)
4) Se n√£o houver entrada clara, recomende aguardar (wait/avoid) e explique o porqu√™.
"""


def _extract_dashscope_text(resp) -> str:
    """Extrai texto de respostas do DashScope."""
    try:
        output = getattr(resp, "output", None)
        if output is None and isinstance(resp, dict):
            output = resp.get("output")
        if not output:
            return ""
        choices = getattr(output, "choices", None)
        if choices is None and isinstance(output, dict):
            choices = output.get("choices")
        if not choices:
            return ""
        choice0 = choices[0]
        message = getattr(choice0, "message", None)
        if message is None and isinstance(choice0, dict):
            message = choice0.get("message")
        content = getattr(message, "content", None)
        if content is None and isinstance(message, dict):
            content = message.get("content")
        if isinstance(content, list) and content:
            for part in content:
                if isinstance(part, dict) and part.get("text"):
                    return str(part["text"]).strip()
        if isinstance(message, str):
            return message.strip()
        return ""
    except Exception:
        return ""


class AIAnalyzer:
    """Analisador de IA com valida√ß√£o robusta de dados e suporte GroqCloud + structured output."""
    
    def __init__(self):
        self.client: Optional[Any] = None        # cliente s√≠ncrono
        self.client_async: Optional[Any] = None  # cliente ass√≠ncrono (AsyncOpenAI)
        self.enabled = False
        self.mode: Optional[str] = None
        self.time_manager = TimeManager()

        # Modelo padr√£o (ser√° sobrescrito se Groq estiver ativo)
        self.model_name = (
            getattr(app_config, "QWEN_MODEL", None)
            or os.getenv("QWEN_MODEL")
            or "qwen-plus"
        )

        self.last_test_time = 0
        self.test_interval_seconds = 120
        self.connection_failed_count = 0
        self.max_failures_before_mock = 3

        logging.info("üß† IA Analyzer v2.3.0 inicializada - GroqCloud + Structured Output focado em regi√µes de entrada")
        try:
            self._initialize_api()
        except Exception as e:
            logging.warning(f"Falha ao inicializar provedores de IA: {e}. Usando mock.")
            self.mode = None
            self.enabled = True

    def _initialize_api(self):
        """
        Inicializa provedores de IA com ordem de prioridade.
        
        ‚úÖ PRIORIDADE:
          1. GroqCloud (r√°pido e barato)
          2. OpenAI (se configurado)
          3. DashScope (fallback)
          4. Mock (√∫ltima op√ß√£o)
        """
        
        # ============================================================
        # üöÄ PRIORIDADE 1: GROQCLOUD
        # ============================================================
        groq_key = os.getenv("GROQ_API_KEY") or getattr(app_config, "GROQ_API_KEY", None)
        
        if OPENAI_AVAILABLE and groq_key:
            # Valida formato da chave
            if not groq_key.startswith("gsk_"):
                logging.warning(
                    f"‚ö†Ô∏è GROQ_API_KEY suspeita (n√£o come√ßa com 'gsk_'). "
                    f"Tentando mesmo assim..."
                )
            
            try:
                # Cliente s√≠ncrono OpenAI-compat√≠vel apontando para Groq
                self.client = OpenAI(
                    api_key=groq_key,
                    base_url="https://api.groq.com/openai/v1"
                )
                # Cliente ass√≠ncrono, se dispon√≠vel
                if ASYNC_OPENAI_AVAILABLE and AsyncOpenAI is not None:
                    self.client_async = AsyncOpenAI(
                        api_key=groq_key,
                        base_url="https://api.groq.com/openai/v1"
                    )
                
                # Sobrescreve model_name com modelo Groq
                self.model_name = (
                    getattr(app_config, "GROQ_MODEL", None)
                    or os.getenv("GROQ_MODEL")
                    or "llama-3.1-70b-versatile"
                )
                
                self.mode = "groq"
                self.enabled = True
                
                logging.info(
                    f"üöÄ GroqCloud ATIVO | Modelo: {self.model_name} | "
                    f"Chave: {groq_key[:10]}...{groq_key[-4:]}"
                )
                return
                
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Groq falhou na inicializa√ß√£o: {e}")
        else:
            if not OPENAI_AVAILABLE:
                logging.debug("OpenAI lib n√£o dispon√≠vel (necess√°ria para Groq)")
            if not groq_key:
                logging.debug("GROQ_API_KEY n√£o encontrada")
        
        # ============================================================
        # PRIORIDADE 2: OPENAI (compatibilidade original)
        # ============================================================
        if OPENAI_AVAILABLE:
            try:
                self.client = OpenAI()  # Usa OPENAI_API_KEY
                if ASYNC_OPENAI_AVAILABLE and AsyncOpenAI is not None:
                    self.client_async = AsyncOpenAI()
                self.mode = "openai"
                self.enabled = True
                logging.info("üîß OpenAI client configurado (modo compat√≠vel)")
                return
            except Exception as e:
                logging.warning(f"OpenAI indispon√≠vel: {e}")

        # ============================================================
        # PRIORIDADE 3: DASHSCOPE (fallback)
        # ============================================================
        token = os.getenv("DASHSCOPE_API_KEY") or getattr(app_config, "DASHSCOPE_API_KEY", None)
        
        if DASHSCOPE_AVAILABLE and token:
            try:
                dashscope.api_key = token
                self.mode = "dashscope"
                self.enabled = True
                logging.info("üîß DashScope configurado (modo nativo - fallback)")
                return
            except Exception as e:
                logging.warning(f"DashScope indispon√≠vel: {e}")

        # ============================================================
        # FALLBACK FINAL: MOCK
        # ============================================================
        self.mode = None
        self.enabled = True
        logging.info("üîß Modo MOCK ativado (sem provedores externos).")

    def _should_test_connection(self) -> bool:
        """Verifica se deve testar conex√£o."""
        now = time.time()
        return (now - self.last_test_time) >= self.test_interval_seconds

    def _test_connection(self) -> bool:
        """Testa conex√£o com IA (ping curto)."""
        if self.mode is None and not self.client:
            try:
                self._initialize_api()
            except Exception:
                pass

        prompt = "Ping curto. Responda com 'OK'."
        try:
            if self.mode == "openai" or self.mode == "groq":
                r = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "Diagn√≥stico curto. Responda apenas 'OK'."},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=3,
                    temperature=0.0,
                    timeout=10,
                )
                content = r.choices[0].message.content.strip().upper()
                success = content.startswith("OK")
                
                if success and self.mode == "groq":
                    logging.debug("‚úÖ Groq ping OK")
                
                return success
                
            elif self.mode == "dashscope":
                r = Generation.call(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "Diagn√≥stico curto. Responda apenas 'OK'."},
                        {"role": "user", "content": prompt},
                    ],
                    result_format="message",
                    max_tokens=3,
                    temperature=0.0,
                    timeout=10,
                )
                content = _extract_dashscope_text(r).upper()
                return content.startswith("OK")
            else:
                return True  # Mock sempre OK
                
        except Exception as e:
            self.connection_failed_count += 1
            logging.warning(
                f"Falha no ping da IA [{self.mode}] ({self.connection_failed_count}): {e}"
            )
            return False

    # ====================================================================
    # üÜï EXTRA√á√ÉO DE DADOS CORRIGIDA (mantido de v2.0.2)
    # ====================================================================
    
    def _extract_orderbook_data(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extrai dados de orderbook de m√∫ltiplas fontes poss√≠veis.
        """
        candidates = [
            event_data.get('orderbook_data'),
            event_data.get('spread_metrics'),
            (event_data.get('contextual_snapshot') or {}).get('orderbook_data'),
            (event_data.get('contextual') or {}).get('orderbook_data'),
        ]
        
        for i, candidate in enumerate(candidates, 1):
            if not isinstance(candidate, dict):
                continue
            
            has_depth = (
                candidate.get('bid_depth_usd') is not None or
                candidate.get('ask_depth_usd') is not None
            )
            
            if has_depth:
                bid_usd = float(candidate.get('bid_depth_usd', 0) or 0)
                ask_usd = float(candidate.get('ask_depth_usd', 0) or 0)
                
                if bid_usd > 0 and ask_usd > 0:
                    logging.debug(f"‚úÖ Orderbook extra√≠do da fonte #{i}: bid=${bid_usd:,.0f}, ask=${ask_usd:,.0f}")
                    return candidate
                else:
                    logging.debug(f"‚ö†Ô∏è Fonte #{i} tem dados zerados (bid=${bid_usd}, ask=${ask_usd})")
        
        logging.warning("‚ö†Ô∏è Nenhuma fonte de orderbook v√°lida encontrada")
        return {}

    # ====================================================================
    # PROMPT BUILDER COM VALIDA√á√ÉO ROBUSTA (usando Jinja2 se dispon√≠vel)
    # ====================================================================
    
    def _render_template(self, template_name: str, context: Dict[str, Any]) -> str:
        """Renderiza template com Jinja2 se dispon√≠vel, sen√£o usa concatena√ß√£o simples."""
        if template_name == "orderbook":
            tmpl_str = ORDERBOOK_TEMPLATE
        else:
            tmpl_str = DEFAULT_TEMPLATE

        if JINJA_AVAILABLE and _jinja_env is not None:
            try:
                tmpl = _jinja_env.from_string(tmpl_str)
                return tmpl.render(**context)
            except Exception as e:
                logging.error(f"Erro ao renderizar template Jinja2: {e}")

        # Fallback simples sem Jinja2
        if template_name == "orderbook":
            return (
                f"üß† **An√°lise Institucional ‚Äì {context['ativo']} | {context['tipo_evento']}**\n\n"
                f"üìù Descri√ß√£o: {context['descricao']}\n"
                f"{context['ob_str']}{context['ml_str']}{context['vp_str']}{context['order_flow_str']}\n\n"
                f"üìà Multi-Timeframes\n{context['multi_tf_str']}\n\n"
                f"‚è≥ Mem√≥ria de eventos\n{context['memoria_str']}\n\n"
                f"üìâ Probabilidade Hist√≥rica\n"
                f"   Long={context['prob_long']} | Short={context['prob_short']} | Neutro={context['prob_neutral']}\n\n"
                "üéØ Tarefa\n"
                "CR√çTICO: Se dados estiverem marcados como \"Indispon√≠vel\" ou \"‚ö†Ô∏è\", N√ÉO os use.\n\n"
                + ("üî¥ ORDERBOOK INDISPON√çVEL - Use APENAS m√©tricas de fluxo (net_flow, flow_imbalance, tick_rule)\n\n"
                   if not context.get("is_orderbook_valid", True) else "")
                + "Foque em identificar regi√µes importantes (suporte/resist√™ncia, absor√ß√£o, exaust√£o, buracos de liquidez)\n"
                "e em sugerir, SE HOUVER clareza, uma regi√£o de entrada e zona de invalida√ß√£o.\n"
                "Se dados cr√≠ticos faltarem, seja expl√≠cito sobre limita√ß√µes.\n"
            )
        else:
            return (
                f"üß† **An√°lise Institucional ‚Äì {context['ativo']} | {context['tipo_evento']}**\n\n"
                f"üìù Descri√ß√£o: {context['descricao']}\n\n"
                f"   Pre√ßo: {context['preco_fmt']}\n"
                f"   Delta: {context['delta_line']}\n"
                f"   Volume: {context['vol_line']}\n"
                f"{context['ml_str']}{context['vp_str']}{context['order_flow_str']}\n\n"
                "üìà Multi-Timeframes\n"
                f"{context['multi_tf_str']}\n\n"
                "‚è≥ Mem√≥ria de eventos\n"
                f"{context['memoria_str']}\n\n"
                "üìâ Probabilidade Hist√≥rica\n"
                f"   Long={context['prob_long']} | Short={context['prob_short']} | Neutro={context['prob_neutral']}\n\n"
                "üéØ Tarefa\n"
                "Use APENAS dados explicitamente fornecidos.\n"
                "Se marcado como \"Indispon√≠vel\", N√ÉO use na an√°lise.\n\n"
                "Foque em:\n"
                "1) For√ßa ou fraqueza do movimento (sentimento).\n"
                "2) Presen√ßa de regi√£o de defesa (suporte/absor√ß√£o) ou oferta (resist√™ncia/exaust√£o).\n"
                "3) Se houver cen√°rios claros, descreva:\n"
                "   - regi√£o aproximada de entrada (entry_zone)\n"
                "   - zona de invalida√ß√£o (invalidation_zone)\n"
                "4) Se n√£o houver entrada clara, recomende aguardar (wait/avoid) e explique o porqu√™.\n"
            )

    def _create_prompt(self, event_data: Dict[str, Any]) -> str:
        """
        Cria prompt para IA com valida√ß√£o de dados.
        """
        tipo_evento = event_data.get("tipo_evento", "N/A")
        ativo = event_data.get("ativo") or event_data.get("symbol") or "N/A"
        descricao = event_data.get("descricao", "Sem descri√ß√£o.")
        
        # Orderbook
        ob_data = self._extract_orderbook_data(event_data)
        bid_usd_raw = float(ob_data.get('bid_depth_usd', 0) or 0)
        ask_usd_raw = float(ob_data.get('ask_depth_usd', 0) or 0)
        is_orderbook_valid = (bid_usd_raw > 0 and ask_usd_raw > 0)
        
        if not is_orderbook_valid:
            logging.warning(
                f"‚ö†Ô∏è Orderbook INV√ÅLIDO para prompt: bid=${bid_usd_raw}, ask=${ask_usd_raw}"
            )
        
        # Delta e volumes
        delta_raw = event_data.get("delta")
        volume_total_raw = event_data.get("volume_total")
        volume_compra_raw = event_data.get("volume_compra")
        volume_venda_raw = event_data.get("volume_venda")
        
        delta = float(delta_raw) if delta_raw is not None else None
        volume_total = float(volume_total_raw) if volume_total_raw is not None else None
        volume_compra = float(volume_compra_raw) if volume_compra_raw is not None else None
        volume_venda = float(volume_venda_raw) if volume_venda_raw is not None else None
        
        # Consist√™ncia delta vs volumes
        if delta is not None and abs(delta) > 1.0:
            if (volume_compra == 0 and volume_venda == 0) or volume_total == 0:
                logging.warning(
                    f"‚ö†Ô∏è Inconsist√™ncia: delta={delta:.2f} mas volumes zerados. "
                    f"Marcando volumes como indispon√≠veis."
                )
                volume_compra = None
                volume_venda = None
                volume_total = None
        
        preco = (
            event_data.get("preco_atual")
            or event_data.get("preco_fechamento")
            or (event_data.get("ohlc", {}) or {}).get("close")
            or 0
        )

        # Multi TF
        multi_tf = (
            event_data.get("multi_tf")
            or event_data.get("contextual_snapshot", {}).get("multi_tf")
            or event_data.get("contextual", {}).get("multi_tf")
            or {}
        )
        multi_tf_str = (
            "\n".join(f"- {tf}: {v}" for tf, v in multi_tf.items()) if multi_tf else "Indispon√≠vel."
        )

        # Mem√≥ria de eventos
        memoria = event_data.get("event_history", [])
        if memoria:
            mem_lines = []
            for e in memoria:
                mem_delta = format_delta(e.get('delta', 0))
                mem_vol = format_large_number(e.get('volume_total', 0))
                mem_lines.append(
                    f"   - {e.get('timestamp')} | {e.get('tipo_evento')} "
                    f"{e.get('resultado_da_batalha')} (Œî={mem_delta}, Vol={mem_vol})"
                )
            memoria_str = "\n".join(mem_lines)
        else:
            memoria_str = "   Nenhum evento recente."

        # Probabilidade hist√≥rica
        conf = event_data.get("historical_confidence", {})
        prob_long = conf.get("long_prob", "Indispon√≠vel")
        prob_short = conf.get("short_prob", "Indispon√≠vel")
        prob_neutral = conf.get("neutral_prob", "Indispon√≠vel")

        # Volume Profile
        vp = (
            event_data.get("historical_vp", {}).get("daily", {})
            or event_data.get("contextual_snapshot", {}).get("historical_vp", {}).get("daily", {})
            or {}
        )
        vp_str = ""
        if vp:
            poc_fmt = format_price(vp.get('poc', 0))
            val_fmt = format_price(vp.get('val', 0))
            vah_fmt = format_price(vp.get('vah', 0))
            vp_str = f"""
üìä Volume Profile (Di√°rio)
   POC: ${poc_fmt} | VAL: ${val_fmt} | VAH: ${vah_fmt}
"""

        # Order flow
        flow = (
            event_data.get("fluxo_continuo")
            or event_data.get("flow_metrics")
            or (event_data.get("contextual_snapshot") or {}).get("flow_metrics")
            or (event_data.get("contextual") or {}).get("flow_metrics")
            or {}
        )
        
        order_flow_str = ""
        if isinstance(flow, dict) and flow:
            of = flow.get("order_flow", {})
            if isinstance(of, dict) and of:
                try:
                    buy_vol = of.get("buy_volume", 0)
                    sell_vol = of.get("sell_volume", 0)
                    bsr = of.get("buy_sell_ratio")
                    
                    has_volumes = (buy_vol > 0 or sell_vol > 0)
                    
                    if not has_volumes and bsr is not None and bsr > 0:
                        logging.warning(
                            f"‚ö†Ô∏è CONTRADI√á√ÉO: buy/sell volumes zero mas ratio={bsr}. "
                            f"Marcando ratio como indispon√≠vel."
                        )
                        bsr = None
                    
                    flow_lines = []
                    
                    # Net flows
                    nf1 = of.get("net_flow_1m")
                    if nf1 is not None:
                        flow_lines.append(f"   Net Flow 1m: {format_delta(nf1)}")
                    
                    # Flow imbalance
                    fi = of.get("flow_imbalance")
                    if fi is not None:
                        flow_lines.append(f"   Flow Imbalance: {format_scientific(fi, 4)}")
                    
                    # Ratio (apenas se v√°lido)
                    if bsr is not None:
                        flow_lines.append(f"   Buy/Sell Ratio: {format_scientific(bsr, 2)}")
                    
                    if flow_lines:
                        order_flow_str = "\nüö∞ Fluxo de Ordens\n" + "\n".join(flow_lines) + "\n"
                
                except Exception as e:
                    logging.error(f"Erro ao processar order_flow: {e}")

        # ML FEATURES
        ml = event_data.get("ml_features") or event_data.get("ml") or {}
        ml_str = ""
        if isinstance(ml, dict) and ml:
            try:
                mf = ml.get("microstructure", {}) or {}
                
                tick_rule = mf.get("tick_rule_sum")
                flow_imb = mf.get("flow_imbalance")
                
                ml_lines = []
                if tick_rule is not None:
                    ml_lines.append(f"   Tick Rule Sum: {format_scientific(tick_rule, 3)}")
                if flow_imb is not None:
                    ml_lines.append(f"   Flow Imbalance: {format_scientific(flow_imb, 4)}")
                
                if ml_lines:
                    ml_str = "\nüìê ML Features\n" + "\n".join(ml_lines) + "\n"
            except Exception:
                pass

        # OrderBook espec√≠fico
        if tipo_evento == "OrderBook" or "imbalance" in event_data:
            if not is_orderbook_valid:
                ob_str = f"""
üìä Evento OrderBook - ‚ö†Ô∏è DADOS INDISPON√çVEIS

üî¥ ATEN√á√ÉO: Orderbook zerado ou inv√°lido
   Bid Depth: ${bid_usd_raw:,.2f}
   Ask Depth: ${ask_usd_raw:,.2f}

‚ö†Ô∏è An√°lise de livro INDISPON√çVEL
   Use APENAS m√©tricas de fluxo se dispon√≠veis:
   - net_flow (delta acumulado)
   - flow_imbalance (propor√ß√£o buy/sell)
   - tick_rule_sum (upticks vs downticks)
"""
            else:
                imbalance = ob_data.get("imbalance", 0)
                mid = ob_data.get("mid", 0)
                spread_pct = ob_data.get("spread_percent", 0)
                
                ob_str = f"""
üìä Evento OrderBook ‚úÖ

   Pre√ßo Mid: {format_price(mid)}
   Spread: {format_percent(spread_pct)}
   
   Profundidade (USD):
   ‚Ä¢ Bids: {format_large_number(bid_usd_raw)}
   ‚Ä¢ Asks: {format_large_number(ask_usd_raw)}
   
   Imbalance: {format_scientific(imbalance, 4)}
"""
            context = {
                "ativo": ativo,
                "tipo_evento": tipo_evento,
                "descricao": descricao,
                "ob_str": ob_str,
                "ml_str": ml_str,
                "vp_str": vp_str,
                "order_flow_str": order_flow_str,
                "multi_tf_str": multi_tf_str,
                "memoria_str": memoria_str,
                "prob_long": prob_long,
                "prob_short": prob_short,
                "prob_neutral": prob_neutral,
                "is_orderbook_valid": is_orderbook_valid,
            }
            return self._render_template("orderbook", context)

        # Prompt padr√£o
        vol_line = (
            "Indispon√≠vel" if volume_total is None 
            else f"{format_large_number(volume_total)}"
        )
        delta_line = f"{format_delta(delta)}" if delta is not None else "Indispon√≠vel"
        preco_fmt = format_price(preco)

        context = {
            "ativo": ativo,
            "tipo_evento": tipo_evento,
            "descricao": descricao,
            "preco_fmt": preco_fmt,
            "delta_line": delta_line,
            "vol_line": vol_line,
            "ml_str": ml_str,
            "vp_str": vp_str,
            "order_flow_str": order_flow_str,
            "multi_tf_str": multi_tf_str,
            "memoria_str": memoria_str,
            "prob_long": prob_long,
            "prob_short": prob_short,
            "prob_neutral": prob_neutral,
        }
        return self._render_template("default", context)

    # ====================================================================
    # CALLERS (SYNC + ASYNC / STRUCTURED)
    # ====================================================================

    async def _a_call_openai_text(self, prompt: str) -> str:
        """Vers√£o ass√≠ncrona simples (texto livre) para OpenAI/Groq."""
        if not self.client_async:
            raise RuntimeError("Cliente ass√≠ncrono n√£o inicializado")
        try:
            response = await self.client_async.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Voc√™ √© analista institucional de fluxo, suporte/resist√™ncia e regi√µes de defesa.\n"
                            "REGRAS:\n"
                            "1) Use SOMENTE dados fornecidos explicitamente.\n"
                            "2) Se marcado 'Indispon√≠vel' ou '‚ö†Ô∏è', N√ÉO use.\n"
                            "3) Orderbook zerado? Use fluxo (net_flow, flow_imbalance, tick_rule).\n"
                            "4) Contradi√ß√µes? Ignore dado contradit√≥rio.\n"
                            "5) Foque em identificar REGI√ïES IMPORTANTES:\n"
                            "   - Suportes e resist√™ncias relevantes\n"
                            "   - Regi√µes de absor√ß√£o (defesa) e exaust√£o (fraqueza)\n"
                            "   - Falta de demanda/oferta (breaks, buracos de liquidez)\n"
                            "6) S√≥ sugira ENTRADA (compra/venda) quando houver uma regi√£o CLARA e bem defendida,\n"
                            "   descrevendo pre√ßo aproximado da entrada e uma zona de invalida√ß√£o.\n"
                            "7) Se o cen√°rio n√£o estiver claro, prefira recomendar 'aguardar' e explique o porqu√™.\n"
                            "8) Seja sucinto, objetivo e profissional."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=700,
                temperature=0.25,
                timeout=30,
            )
            if response.choices and len(response.choices) > 0:
                content = response.choices[0].message.content.strip()
                return content
            return ""
        except Exception as e:
            logging.error(f"Erro ass√≠ncrono {self.mode} (texto): {e}")
            return ""

    async def _a_call_openai_structured(self, prompt: str) -> tuple[str, Optional[AITradeAnalysis]]:
        """
        Vers√£o ass√≠ncrona usando JSON Mode + Pydantic.
        Retorna (raw_json_string, objeto_validado_ou_None).
        """
        if not self.client_async:
            raise RuntimeError("Cliente ass√≠ncrono n√£o inicializado")
        if not (PYDANTIC_AVAILABLE and AITradeAnalysis):
            text = await self._a_call_openai_text(prompt)
            return text, None
        try:
            response = await self.client_async.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Voc√™ √© analista institucional de fluxo, suporte/resist√™ncia e regi√µes de defesa.\n"
                            "Responda APENAS em JSON com os campos:\n"
                            "sentiment (bullish/bearish/neutral),\n"
                            "confidence (0-1),\n"
                            "action (buy/sell/hold/flat/wait/avoid),\n"
                            "rationale (string),\n"
                            "entry_zone (string ou null),\n"
                            "invalidation_zone (string ou null),\n"
                            "region_type (string ou null, ex: 'suporte', 'resist√™ncia', 'absor√ß√£o', 'exaust√£o').\n"
                            "Regras:\n"
                            "- S√≥ indique entry_zone se houver uma regi√£o CLARA de entrada (defesa institucional, suporte/resist√™ncia relevante, absor√ß√£o/exaust√£o bem formadas).\n"
                            "- Se o cen√°rio n√£o estiver claro, use action='wait' ou 'avoid' e entry_zone=null.\n"
                            "- N√£o inclua texto fora do JSON."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=400,
                temperature=0.25,
                timeout=30,
                response_format={"type": "json_object"},
            )
            if not response.choices:
                return "", None
            content = response.choices[0].message.content.strip()
            if not content:
                return "", None
            try:
                if hasattr(AITradeAnalysis, "model_validate_json"):
                    obj = AITradeAnalysis.model_validate_json(content)  # type: ignore[attr-defined]
                else:
                    obj = AITradeAnalysis.parse_raw(content)           # type: ignore[attr-defined]
                return content, obj
            except Exception as e:
                logging.warning(f"Falha ao parsear JSON structured: {e}. Usando apenas texto.")
                return content, None
        except Exception as e:
            logging.error(f"Erro JSON Mode {self.mode}: {e}. Fallback texto.")
            text = await self._a_call_openai_text(prompt)
            return text, None

    def _call_openai_compatible(self, prompt: str, max_retries: int = 3) -> str:
        """
        Chama cliente OpenAI-compat√≠vel de forma s√≠ncrona (texto livre).
        Mantido para fallback e para ping.
        """
        base_delay = 1.0
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                "Voc√™ √© analista institucional de fluxo, suporte/resist√™ncia e regi√µes de defesa.\n"
                                "REGRAS:\n"
                                "1) Use SOMENTE dados fornecidos explicitamente.\n"
                                "2) Se marcado 'Indispon√≠vel' ou '‚ö†Ô∏è', N√ÉO use.\n"
                                "3) Orderbook zerado? Use fluxo (net_flow, flow_imbalance, tick_rule).\n"
                                "4) Contradi√ß√µes? Ignore dado contradit√≥rio.\n"
                                "5) Foque em identificar REGI√ïES IMPORTANTES:\n"
                                "   - Suportes e resist√™ncias relevantes\n"
                                "   - Regi√µes de absor√ß√£o (defesa) e exaust√£o (fraqueza)\n"
                                "   - Falta de demanda/oferta (breaks, buracos de liquidez)\n"
                                "6) S√≥ sugira ENTRADA (compra/venda) quando houver uma regi√£o CLARA e bem defendida,\n"
                                "   descrevendo pre√ßo aproximado da entrada e uma zona de invalida√ß√£o.\n"
                                "7) Se o cen√°rio n√£o estiver claro, prefira recomendar 'aguardar' e explique o porqu√™.\n"
                                "8) Seja sucinto, objetivo e profissional."
                            ),
                        },
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=700,
                    temperature=0.25,
                    timeout=30,
                )
                if response.choices and len(response.choices) > 0:
                    content = response.choices[0].message.content.strip()
                    if len(content) > 10:
                        if self.mode == "groq":
                            logging.debug(f"‚úÖ Groq respondeu ({len(content)} chars)")
                        return content
                return ""
            except Exception as e:
                logging.error(
                    f"Erro {self.mode.upper()} (tentativa {attempt+1}/{max_retries}): {e}"
                )
                if attempt < max_retries - 1:
                    time.sleep(base_delay * (2 ** attempt))
        return ""

    def _call_dashscope(self, prompt: str, max_retries: int = 3) -> str:
        """Chama DashScope API com retry (texto livre)."""
        base_delay = 1.0
        for attempt in range(max_retries):
            try:
                response = Generation.call(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                "Voc√™ √© analista institucional de fluxo, suporte/resist√™ncia e regi√µes de defesa.\n"
                                "REGRAS:\n"
                                "1) Use SOMENTE dados fornecidos explicitamente.\n"
                                "2) Se marcado 'Indispon√≠vel' ou '‚ö†Ô∏è', N√ÉO use.\n"
                                "3) Orderbook zerado? Use fluxo (net_flow, flow_imbalance, tick_rule).\n"
                                "4) Contradi√ß√µes? Ignore dado contradit√≥rio.\n"
                                "5) Foque em identificar REGI√ïES IMPORTANTES:\n"
                                "   - Suportes e resist√™ncias relevantes\n"
                                "   - Regi√µes de absor√ß√£o (defesa) e exaust√£o (fraqueza)\n"
                                "   - Falta de demanda/oferta (breaks, buracos de liquidez)\n"
                                "6) S√≥ sugira ENTRADA (compra/venda) quando houver uma regi√£o CLARA e bem defendida,\n"
                                "   descrevendo pre√ßo aproximado da entrada e uma zona de invalida√ß√£o.\n"
                                "7) Se o cen√°rio n√£o estiver claro, prefira recomendar 'aguardar' e explique o porqu√™.\n"
                                "8) Seja sucinto, objetivo e profissional."
                            ),
                        },
                        {"role": "user", "content": prompt},
                    ],
                    result_format="message",
                    max_tokens=700,
                    temperature=0.25,
                    timeout=30,
                )
                content = _extract_dashscope_text(response).strip()
                if len(content) > 10:
                    return content
                return ""
            except Exception as e:
                logging.error(f"Erro DashScope (tentativa {attempt+1}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(base_delay * (2 ** attempt))
        return ""

    def _call_model(self, prompt: str, event_data: Dict[str, Any]) -> tuple[str, Optional[Any]]:
        """
        Chama o provedor atual e retorna (raw_response, structured_or_None).
        """
        # Preferir JSON Mode + AsyncOpenAI se dispon√≠vel
        if self.mode in ("openai", "groq") and self.client_async and PYDANTIC_AVAILABLE and AITradeAnalysis:
            try:
                raw, structured = asyncio.run(self._a_call_openai_structured(prompt))
                if raw:
                    return raw, structured
            except Exception as e:
                logging.error(f"Erro ao usar AsyncOpenAI structured: {e}")
                # Fallback para cliente s√≠ncrono
                try:
                    text = self._call_openai_compatible(prompt)
                    return text, None
                except Exception as e2:
                    logging.error(f"Erro fallback sync OpenAI: {e2}")
                    return self._generate_mock_analysis(event_data), None

        # Sem JSON Mode ou sem Async: usar cliente s√≠ncrono
        if self.mode in ("openai", "groq") and self.client:
            text = self._call_openai_compatible(prompt)
            return text, None
        elif self.mode == "dashscope":
            text = self._call_dashscope(prompt)
            return text, None
        else:
            text = self._generate_mock_analysis(event_data)
            return text, None

    def _generate_mock_analysis(self, event_data: Dict[str, Any]) -> str:
        """Gera an√°lise mock quando IA indispon√≠vel."""
        timestamp = self.time_manager.now_iso()
        mock_price = format_price(event_data.get('preco_fechamento', 0))
        mock_delta = format_delta(event_data.get('delta', 0))
        
        return (
            f"**Interpreta√ß√£o (mock):** {event_data.get('tipo_evento')} em "
            f"{event_data.get('ativo')} √†s {timestamp}.\n"
            f"Pre√ßo: ${mock_price} | Delta: {mock_delta}\n"
            f"**For√ßa:** {event_data.get('resultado_da_batalha')}\n"
            f"**Expectativa:** Monitorar rea√ß√£o (dados limitados - modo mock)."
        )

    # ====================================================================
    # N√öCLEO DE AN√ÅLISE (compartilhado entre analyze_event e analyze)
    # ====================================================================

    def _analyze_internal(self, event_data: Dict[str, Any]) -> tuple[str, Optional[Any]]:
        """
        N√∫cleo de an√°lise: constr√≥i prompt, chama modelo e retorna (texto, structured).
        """
        if not self.enabled:
            try:
                self._initialize_api()
            except Exception:
                pass
        
        if not self.enabled:
            return self._generate_mock_analysis(event_data), None

        if self._should_test_connection():
            self.last_test_time = time.time()
            if not self._test_connection():
                if self.connection_failed_count >= self.max_failures_before_mock:
                    return self._generate_mock_analysis(event_data), None

        try:
            prompt = self._create_prompt(event_data)
        except Exception as e:
            logging.error(f"Erro ao criar prompt: {e}", exc_info=True)
            return self._generate_mock_analysis(event_data), None

        try:
            raw, structured = self._call_model(prompt, event_data)
        except Exception as e:
            logging.error(f"Erro na chamada de IA: {e}", exc_info=True)
            raw, structured = self._generate_mock_analysis(event_data), None

        if not raw:
            raw = self._generate_mock_analysis(event_data)
        return raw, structured

    # ====================================================================
    # INTERFACE P√öBLICA
    # ====================================================================
    
    def analyze_event(self, event_data: Dict[str, Any]) -> str:
        """
        Analisa evento e retorna an√°lise da IA (string).
        Mantido para compatibilidade com c√≥digo legado.
        """
        try:
            analysis_text, _ = self._analyze_internal(event_data)
            return analysis_text
        except Exception as e:
            logging.error(f"Erro em analyze_event(): {e}", exc_info=True)
            return self._generate_mock_analysis(event_data)

    def analyze(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa evento e retorna resultado estruturado.

        Retorno:
            {
              "raw_response": str,
              "structured": dict | None,  # se JSON Mode + Pydantic dispon√≠veis
              "tipo_evento": str,
              "ativo": str,
              "timestamp": str,
              "success": bool,
              "mode": str,
              "model": str,
              "error": str (opcional)
            }
        """
        try:
            analysis_text, structured = self._analyze_internal(event_data)
            
            tipo_evento = event_data.get("tipo_evento", "N/A")
            ativo = event_data.get("ativo") or event_data.get("symbol") or "N/A"
            
            logging.info(f"‚úÖ IA [{self.mode or 'mock'}] analisou: {tipo_evento} - {ativo}")
            
            return {
                "raw_response": analysis_text,
                "structured": (
                    structured.model_dump() if (PYDANTIC_AVAILABLE and structured is not None) else None
                ),
                "tipo_evento": tipo_evento,
                "ativo": ativo,
                "timestamp": self.time_manager.now_iso(),
                "success": True,
                "mode": self.mode or "mock",
                "model": self.model_name,
            }
            
        except Exception as e:
            logging.error(f"‚ùå Erro em analyze(): {e}", exc_info=True)
            return {
                "raw_response": f"‚ùå Erro ao analisar evento: {str(e)}",
                "structured": None,
                "tipo_evento": event_data.get("tipo_evento", "N/A"),
                "ativo": event_data.get("ativo") or event_data.get("symbol") or "N/A",
                "timestamp": self.time_manager.now_iso(),
                "success": False,
                "error": str(e),
                "mode": self.mode or "mock",
                "model": self.model_name,
            }

    def close(self):
        """Fecha conex√£o com IA."""
        if self.mode == "groq":
            logging.info("üîå Desconectando GroqCloud...")
        self.client = None
        self.client_async = None

    def __del__(self):
        try:
            self.close()
        except Exception:
            pass


# ====================================================================
# üß™ TESTE DE VALIDA√á√ÉO (executar diretamente)
# ====================================================================

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("üß™ TESTANDO AI_ANALYZER v2.3.0 (GroqCloud + Structured Output focado em regi√µes)")
    print("=" * 70)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(message)s'
    )
    
    analyzer = AIAnalyzer()
    
    print(f"\n‚úÖ Modo ativo: {analyzer.mode or 'MOCK'}")
    print(f"‚úÖ Modelo: {analyzer.model_name}")
    print(f"‚úÖ Enabled: {analyzer.enabled}")
    
    if analyzer.mode:
        print("\nüîç Testando conex√£o...")
        if analyzer._test_connection():
            print("‚úÖ Conex√£o OK!")
        else:
            print("‚ùå Falha na conex√£o")
    
    print("\nüìù Testando an√°lise...")
    mock_event = {
        "tipo_evento": "Absor√ß√£o",
        "ativo": "BTCUSDT",
        "delta": -15.5,
        "volume_total": 125.3,
        "preco_fechamento": 95000,
        "resultado_da_batalha": "Vendedores",
    }
    
    result = analyzer.analyze(mock_event)
    
    print(f"\nüìä Resultado:")
    print(f"  Success: {result['success']}")
    print(f"  Modo: {result.get('mode', 'N/A')}")
    print(f"  Modelo: {result.get('model', 'N/A')}")
    print(f"  Structured: {result.get('structured')}")
    print(f"  Resposta ({len(result['raw_response'])} chars):")
    print(f"  {result['raw_response'][:300]}...")
    
    print("\n" + "=" * 70)
    print("‚úÖ TESTE CONCLU√çDO")
    print("=" * 70 + "\n")