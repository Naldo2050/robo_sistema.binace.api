# diagnostics/verify_ml_integration.py
import sys
import os
import logging
import time
import json
from pathlib import Path
from typing import Dict, Any

# Adiciona raiz ao path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("MLCheck")

def test_ml_engine_direct():
    """Testa diretamente o MLInferenceEngine sem dependÃªncias externas."""
    logger.info("ðŸ§  TESTE DIRETO DO MOTOR DE INFERÃŠNCIA ML")
    print("="*60)
    
    # 1. Verifica se os arquivos existem
    files_to_check = [
        "ml/inference_engine.py",
        "market_orchestrator/ai/ai_payload_builder.py",
    ]
    
    # Verifica modelo ML (opcional para teste)
    model_files = [
        "ml/models/xgb_model_latest.json",
        "ml/models/model_metadata.json"
    ]
    
    missing = [f for f in files_to_check if not os.path.exists(f)]
    if missing:
        logger.error(f"âŒ Arquivos crÃ­ticos faltando: {missing}")
        return False
    
    model_missing = [f for f in model_files if not os.path.exists(f)]
    if model_missing:
        logger.warning(f"âš ï¸ Arquivos de modelo faltando: {model_missing}")
        logger.warning("   O sistema funcionarÃ¡ apenas com IA Generativa")
    
    # 2. Testa importaÃ§Ã£o do MLInferenceEngine
    try:
        from ml.inference_engine import MLInferenceEngine
        logger.info("âœ… MLInferenceEngine importado com sucesso")
    except ImportError as e:
        logger.error(f"âŒ Falha ao importar MLInferenceEngine: {e}")
        return False
    
    # 3. Testa inicializaÃ§Ã£o do motor
    try:
        ml_engine = MLInferenceEngine()
        
        if ml_engine.model is None:
            logger.warning("âš ï¸ Modelo ML nÃ£o carregado (pode nÃ£o existir ou estar corrompido)")
            logger.info("âœ… Sistema pode continuar apenas com IA Generativa")
            return True  # NÃ£o Ã© fatal
            
        logger.info(f"âœ… ML Engine carregado com {len(ml_engine.features)} features")
        
        # 4. Testa extraÃ§Ã£o de features
        test_event = {
            "tipo_evento": "AbsorÃ§Ã£o",
            "ativo": "BTCUSDT",
            "delta": -15.5,
            "volume_total": 125.3,
            "volume_ratio": 1.2,
            "preco_fechamento": 95000,
            "fluxo_continuo": {
                "microstructure": {
                    "tick_rule_sum": 0.2,
                    "flow_imbalance": 0.1,
                    "aggressive_buy_ratio": 0.6,
                    "aggressive_sell_ratio": 0.4
                },
                "whale_activity": {
                    "whale_delta": 0.3,
                    "whale_buy_ratio": 0.7
                }
            },
            "orderbook_data": {
                "bid_ask_ratio": 1.1,
                "imbalance": 0.05,
                "spread_percent": 0.01
            },
            "ohlc": {
                "close": 95000,
                "high": 95500,
                "low": 94500
            }
        }
        
        features = ml_engine.extract_ml_features(test_event)
        logger.info(f"âœ… ExtraÃ­das {len(features)} features do evento")
        
        # 5. Testa previsÃ£o
        prediction = ml_engine.predict(test_event)
        
        if prediction.get("status") == "ok":
            prob = prediction.get("prob_up", 0.5)
            confidence = prediction.get("confidence", 0.0)
            
            logger.info(f"âœ… PrevisÃ£o ML bem-sucedida!")
            logger.info(f"   ðŸ“ˆ Probabilidade de Alta: {prob:.1%}")
            logger.info(f"   ðŸ“Š ConfianÃ§a: {confidence:.1%}")
            logger.info(f"   ðŸ” Features usadas: {prediction.get('features_used')}/{prediction.get('total_features')}")
            
            # InterpretaÃ§Ã£o
            if prob > 0.6:
                bias = "BULLISH (Altista)"
            elif prob < 0.4:
                bias = "BEARISH (Baixista)"
            else:
                bias = "NEUTRAL (Neutro)"
                
            logger.info(f"   ðŸŽ¯ ViÃ©s: {bias}")
            
        else:
            logger.warning(f"âš ï¸ PrevisÃ£o falhou: {prediction.get('status')}")
            if prediction.get("msg"):
                logger.warning(f"   Erro: {prediction.get('msg')}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro ao testar ML Engine: {e}", exc_info=True)
        return False

def test_payload_builder():
    """Testa se o payload builder foi atualizado para suportar ML."""
    logger.info("\nðŸ“¦ TESTANDO ATUALIZAÃ‡ÃƒO DO PAYLOAD BUILDER")
    print("-"*40)
    
    try:
        # Importa o builder diretamente
        import market_orchestrator.ai.ai_payload_builder as builder_module
        
        # Verifica se a funÃ§Ã£o build_ai_input tem o parÃ¢metro ml_prediction
        import inspect
        sig = inspect.signature(builder_module.build_ai_input)
        params = list(sig.parameters.keys())
        
        if "ml_prediction" in params:
            logger.info("âœ… Payload builder atualizado com parÃ¢metro 'ml_prediction'")
            
            # Testa chamada com ml_prediction
            test_payload = builder_module.build_ai_input(
                symbol="BTCUSDT",
                signal={"tipo_evento": "Teste", "descricao": "Teste"},
                enriched={},
                flow_metrics={},
                historical_profile={},
                macro_context={},
                market_environment={},
                orderbook_data={},
                ml_features={},
                ml_prediction={"status": "ok", "prob_up": 0.75, "confidence": 0.8}
            )
            
            if "quant_model" in test_payload:
                logger.info("âœ… SeÃ§Ã£o 'quant_model' adicionada ao payload")
                logger.info(f"   ViÃ©s: {test_payload['quant_model'].get('model_sentiment', 'N/A')}")
            else:
                logger.error("âŒ SeÃ§Ã£o 'quant_model' nÃ£o encontrada no payload")
                return False
                
            if "ml_str" in test_payload:
                logger.info("âœ… String ML formatada criada para templates")
            else:
                logger.warning("âš ï¸ 'ml_str' nÃ£o encontrada no payload")
                
            return True
            
        else:
            logger.error("âŒ Payload builder NÃƒO atualizado - falta parÃ¢metro 'ml_prediction'")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro ao testar payload builder: {e}", exc_info=True)
        return False

def test_ai_runner_integration():
    """Verifica se o ai_runner.py foi atualizado."""
    logger.info("\nâš™ï¸ VERIFICANDO ATUALIZAÃ‡ÃƒO DO AI_RUNNER")
    print("-"*40)
    
    try:
        with open("market_orchestrator/ai/ai_runner.py", "r", encoding="utf-8") as f:
            content = f.read()
        
        checks = [
            ("from ml.inference_engine import MLInferenceEngine", "ImportaÃ§Ã£o do ML Engine"),
            ("bot.ml_engine = MLInferenceEngine()", "InicializaÃ§Ã£o do ML Engine"),
            ("ml_prediction = bot.ml_engine.predict", "Chamada de previsÃ£o ML"),
            ('event_data["ml_prediction"] = ml_prediction', "InjeÃ§Ã£o no event_data"),
            ("ml_prediction=ml_prediction", "Passagem para builder")
        ]
        
        all_passed = True
        for check_str, description in checks:
            if check_str in content:
                logger.info(f"âœ… {description} encontrado")
            else:
                logger.error(f"âŒ {description} NÃƒO encontrado")
                all_passed = False
        
        return all_passed
        
    except Exception as e:
        logger.error(f"âŒ Erro ao verificar ai_runner: {e}", exc_info=True)
        return False

def generate_test_report():
    """Gera relatÃ³rio completo de teste."""
    logger.info("\nðŸ“‹ RELATÃ“RIO DE VERIFICAÃ‡ÃƒO DA INTEGRAÃ‡ÃƒO ML")
    print("="*60)
    
    results = []
    
    # Teste 1: Motor ML
    logger.info("\n1. Testando Motor de InferÃªncia ML...")
    ml_ok = test_ml_engine_direct()
    results.append(("Motor ML", ml_ok))
    
    # Teste 2: Payload Builder
    logger.info("\n2. Testando Payload Builder...")
    builder_ok = test_payload_builder()
    results.append(("Payload Builder", builder_ok))
    
    # Teste 3: AI Runner
    logger.info("\n3. Verificando AI Runner...")
    runner_ok = test_ai_runner_integration()
    results.append(("AI Runner", runner_ok))
    
    # RelatÃ³rio final
    logger.info("\n" + "="*60)
    logger.info("ðŸ“Š RESUMO DOS TESTES")
    print("-"*40)
    
    all_passed = True
    for test_name, passed in results:
        status = "âœ… PASSOU" if passed else "âŒ FALHOU"
        logger.info(f"{test_name}: {status}")
        if not passed:
            all_passed = False
    
    print("-"*40)
    if all_passed:
        logger.info("ðŸŽ‰ TODOS OS TESTES PASSARAM! Sistema pronto para InteligÃªncia HÃ­brida.")
        logger.info("   O robÃ´ usarÃ¡ ML Quantitativo + IA Generativa.")
    else:
        logger.info("âš ï¸  ALGUNS TESTES FALHARAM. Sistema funcionarÃ¡ apenas com IA Generativa.")
        logger.info("   Verifique os erros acima e corrija.")
    
    return all_passed

if __name__ == "__main__":
    success = generate_test_report()
    sys.exit(0 if success else 1)